# SPDX-FileCopyrightText: : 2025 The PyPSA-China Authors
# SPDX-License-Identifier: MIT

import yaml
import shutil
from pathlib import Path
from snakemake.utils import min_version
import logging
import os.path
import logging

from scripts._helpers import PathManager, get_cutout_params, ConfigManager

# NB: duplicated parameters will be overwritten by the last read cfg

configfile: "config/default_config.yaml"
configfile: "config/technology_config.yaml"
configfile: "config/plot_config.yaml"
configfile: "config/global_energy_monitor.yaml"

# for dev of remind with mocksnakemake, can activate this
# configfile: "resources/tmp/remind_coupled_cg.yaml"


# ====== make paths =======
config_manager = ConfigManager(config)
config = config_manager.handle_scenarios()

# ====== set global parameters =======
ATLITE_NPROCESSES = config['atlite'].get('nprocesses', 4)
CUTOUT_NAME= config["atlite"]["cutout_name"]
# for pathways, first point should be near-fixed by existing capacities and is baseyear
# for overnight it refers to existing infrastructure
BASEYEAR = min([int(y) for y in config["scenario"]["planning_horizons"]])

# ====== make paths =======
path_manager = PathManager(config)
RESULTS_DIR = path_manager.results_dir()
DERIVED_DATA = path_manager.derived_data_dir(shared=False)
DERIVED_COMMON = path_manager.derived_data_dir(shared=True)
DERIVED_CUTOUT = DERIVED_COMMON + f"/cutout_{CUTOUT_NAME}"
COSTS_DATA = path_manager.costs_dir()
LOG_DIR = path_manager.logs_dir()
LOGS_COMMON = "logs"
LU_RASTER = path_manager.landuse_raster_data()
CUTOUT_PATH = os.path.join(path_manager.cutouts_dir(),CUTOUT_NAME + ".nc")

# ====== include rules ======= (after paths are set!)
include: "rules/prepare_remind_coupled.smk"
include: "rules/postprocess.smk"
include: "rules/fetch_data.smk"
include: "rules/visualize_inputs.smk"

if config["run"].get("is_test", False):
    localrules: plot_all, plot_summary, plot_snapshots, build_population, dag, fetch_region_shapes, plot_input_costs

# ====== set up snakemake providers =======
storage:
    provider="http",

# ======= PSEUDO RULES TO EXECUTE WORKFLOW =========
if config["run"].get("is_test", False):
    rule test_workflow:
        input:
            expand(RESULTS_DIR+ '/postnetworks/ntwk_{planning_horizons}.nc',
            **{k: v for k, v in config["scenario"].items() if k != "planing_horizons"},
            ),

elif config["foresight"] in ["overnight", "myopic"]:
    rule plot_all:
        input:
            expand(
                RESULTS_DIR+ '/plots/summary/pathway_costs.png',
                **{k: v for k, v in config["scenario"].items() if k != "planning_horizons"},
            ),
            # network plot
            expand(
                RESULTS_DIR+"/plots/networks/ntwk_{planning_horizons}-cost.png",
                **config["scenario"]
            ),
            expand(RESULTS_DIR+"/plots/statistics_{planning_horizons}/", **config["scenario"]),
            expand(RESULTS_DIR + "/plots/snapshots_{planning_horizons}/", **config["scenario"]),
else:
    raise ValueError("Invalid scenario config: {}".format(config["foresight"]))

rule process_config:
    output:
        config="config_test.yaml"
    script:
        "scripts/process_config.py"
#    ======== Workflow ===========
rule build_population:
    input:
        # https://www.stats.gov.cn/sj/ndsj/2023/indexeh.htm
        population="resources/data/population/population_from_national_data.csv"
    output:
        population=DERIVED_COMMON+"/"+"population/population.h5"
    threads: 1
    resources: mem_mb=1000
    log: LOGS_COMMON + "/build_population.log"
    script: "scripts/build_population.py"

if config['enable'].get('build_cutout', False):
    rule build_cutout:
        input:
            regions_onshore="resources/data/regions/regions_onshore.geojson",
            regions_offshore="resources/data/regions/regions_offshore.geojson"
        output: CUTOUT_PATH,
        log: LOGS_COMMON + f"/build_cutout/{CUTOUT_NAME}.log"
        benchmark: f"benchmarks/build_cutout_{CUTOUT_NAME}"
        threads: ATLITE_NPROCESSES
        resources: mem_mb=ATLITE_NPROCESSES * 1000
        script: "scripts/build_cutout.py"

rule build_population_gridcell_map:
    input:
        cutout=CUTOUT_PATH,
        province_populations=DERIVED_COMMON+"/population/population.h5",
        population_density_grid="resources/data/population/pop_density_china.nc",
        # TODO directly link to output of fetch region shapes
        # admin 1 level = first administrative level within country
        province_shape=DERIVED_COMMON+"/province_shapes/CHN_adm1.shp",
    output:
        population_map=DERIVED_COMMON+"/"+"population/population_gridcell_map.h5"
    log: LOGS_COMMON+"/build_population_gridcell_map.log"
    threads: 1
    resources: mem_mb=35000
    script: "scripts/build_population_gridcell_map.py"

# TODO merge all techs into a single csv
# TODO add node wildcard/id
brownfield_techs = config["existing_capacities"]["techs"]
rule build_powerplants:
    """ Groups power plants by node"""
    params:
        nodes = config["nodes"],
        gem = config["global_energy_monitor_plants"],
    input:
        GEM_plant_tracker="resources/data/existing_infrastructure/gem_data_raw/Global-integrated-Plant-Tracker-July-2025_china.xlsx",
        nodes=DERIVED_COMMON + "/regions/provinces_onshore.geojson",
    output:
        **{tech : DERIVED_COMMON + f"/existing_infrastructure/{tech}_capacity.csv" for tech in brownfield_techs},
    log: LOGS_COMMON + "/build_powerplants.log"
    threads: 2 #TODO 1?
    script: "scripts/build_powerplants.py"

# TODO find a way to turn off if heat coupling is off
rule build_solar_thermal_profiles:
    input:
        cutout=CUTOUT_PATH,
        population_map=DERIVED_COMMON+"/"+"population/population_gridcell_map.h5"
    output:
        profile_solar_thermal = DERIVED_CUTOUT+f"/heating/solar_thermal-{config['solar_thermal_angle']}.h5"
    log: LOGS_COMMON + "/build_solar_thermal_profiles.log"
    threads: 8
    resources: mem_mb=30000
    script: "scripts/build_solar_thermal_profiles.py"

rule build_temperature_profiles:
    input:
        population_map=DERIVED_COMMON+"/"+"population/population_gridcell_map.h5",
        cutout=CUTOUT_PATH
    output:
        temp= DERIVED_CUTOUT + "/heating/temperature.h5"
    log: LOGS_COMMON + "/build_temperature_profiles.log"
    threads: 8
    resources: mem_mb=30000
    script: "scripts/build_temperature_profiles.py"

rule build_cop_profiles:
    input:
        population_map=DERIVED_COMMON+"/"+"population/population_gridcell_map.h5",
        cutout=CUTOUT_PATH,
        temperature=DERIVED_CUTOUT + "/heating/temperature.h5"
    output:
        cop= DERIVED_CUTOUT + "/heating/hp_cop.h5"
    threads: 8
    resources: mem_mb=30000
    log: LOGS_COMMON + "/build_cop_profiles.log"
    script: "scripts/build_cop_profiles.py"

rasters = ["Build_up", "Grass", "Bare", "Shrubland"]
rule build_availability_matrix:
    input:
        # GEBCO bathymetry (water depth)
        gebco=f"{LU_RASTER}/GEBCO_tiff/gebco_2024_CN.tif",
        cutout=CUTOUT_PATH,
        # TODO directly link to output of fetch region shapes
        # admin 1 level = first administrative level within country
        province_shape=DERIVED_COMMON+"/province_shapes/CHN_adm1.shp",
        offshore_province_shapes=DERIVED_COMMON + "/regions/provinces_offshore.geojson",
        # natural reserves from WPGDA, available land
        **{
            f"natura{i+1}": "resources/data/landuse_availability/"
                        + f"WDPA_WDOECM_Oct2024_Public_CN_shp_{i}/"
                        + "WDPA_WDOECM_Oct2024_Public_CN_shp-polygons.shp"
            for i in range(3)
        },
        # available land:
        **{
            f"{raster}_raster": f"{LU_RASTER}/{raster}.tif"
            for raster in rasters
        },
    output:
        availability_matrix= DERIVED_CUTOUT + "/availability_matrix_{technology}.nc",
    log: LOGS_COMMON + "/build_availability_matrix_{technology}.log"
    script: "scripts/determine_availability_matrix.py"


rule build_renewable_profiles:
    params:
        resource_classes = lambda wildcards: config["renewable"][wildcards.technology]["resource_classes"]
    input:
        availability_matrix= DERIVED_CUTOUT + "/availability_matrix_{technology}.nc",
        province_shape=DERIVED_COMMON + "/province_shapes/CHN_adm1.shp",
        offshore_province_shapes=DERIVED_COMMON + "/regions/provinces_offshore.geojson",
        cutout=CUTOUT_PATH,
    output:
        profile=DERIVED_CUTOUT+"/"+"profile_{technology}-{rc_params}.nc",
        class_regions=DERIVED_CUTOUT+"/"+"{technology}_regions_by_class_{rc_params}.geojson",
        average_distance=DERIVED_CUTOUT+"/"+"average_distance_{technology}-{rc_params}.h5",
    log:
        LOGS_COMMON +f"/cutout_{CUTOUT_NAME}/" +"build_renewable_profile_{technology}-{rc_params}.log",
    threads: config["atlite"].get("nprocesses", 4)
    wildcard_constraints:
        technology="(?!hydro).*",  # Any technology other than hydro
    script:
        "scripts/build_renewable_profiles.py"

# TODO check whether energy totals still needed
rule build_load_profiles:
    params:
        elec_load_conversion = config["paths"]["yearly_regional_load"]["ac_to_mwh"]
    input:
        population = DERIVED_COMMON + "/population/population.h5",
        population_map = DERIVED_COMMON + "/population/population_gridcell_map.h5",
        cutout = CUTOUT_PATH,
        intraday_profiles="resources/data/heating/heat_load_profile_DK_AdamJensen.csv",
        space_heat_demand="resources/data/heating/SPH_2020.csv",
        elec_load_projs = path_manager.elec_load(),
        province_codes = "resources/data/regions/province_codes.csv",
        hrly_regional_ac_load = "resources/data/load/Hourly_demand_of_31_province_China_modified_V2.1.csv",
    output:
        # TODO consider splitting into two rules so elect+hrly can be used DERIVED COMMON
        elec_load_hrly = DERIVED_DATA + "/load/regio_hrly_ac_load_{planning_horizons}.h5",
        heat_demand_profile = DERIVED_DATA + f"/heating-cutout_{CUTOUT_NAME}/"+"heat_demand_profile_{planning_horizons}.h5",
        energy_totals_name = DERIVED_DATA + "/" +f"energy_totals_{CUTOUT_NAME}_"+"{planning_horizons}.h5"
    log: LOG_DIR + "/build_load_profiles/build_{planning_horizons}"+f"_{CUTOUT_NAME}.log"
    threads: ATLITE_NPROCESSES
    resources: mem_mb = ATLITE_NPROCESSES * 5000
    script: "scripts/build_load_profiles.py"

# Only build transport demand if electric vehicles are enabled
if config.get("sectors", {}).get("electric_vehicles", False):
    if not config["run"].get("is_remind_coupled", False):
        raise ValueError(
            "Electric vehicles require REMIND data for transport demand.\n"
            "Please choose one of the following:\n"
            "1. Set 'run.is_remind_coupled: true' and provide REMIND data files\n"
            "2. Set 'sectors.electric_vehicles: false' to run electricity-only model"
        )
    rule build_transport_demand:
        params:
            snapshots=config["snapshots"],
            EV_pass=config.get("transport", {}).get("passenger_bev", {}),
            EV_freight=config.get("transport", {}).get("freight_bev", {}),
            DSM_config=config.get("DSM_config", {}),
        input:
            driving_data_passenger="resources/data/load/driving_ratio_passenger.csv",
            driving_data_freight="resources/data/load/driving_ratio_freight.csv",
            charging_data_passenger="resources/data/load/charging_ratio_passenger.csv",
            charging_data_freight="resources/data/load/charging_ratio_freight.csv",
            availability_data_passenger="resources/data/load/availability_ratio_passenger.csv",
            availability_data_freight="resources/data/load/availability_ratio_freight.csv",
            sectoral_load=DERIVED_DATA + "/remind/ac_load_disagg.csv" if config["run"].get("is_remind_coupled", False) else DERIVED_DATA + "/load/regio_hrly_ac_load_{planning_horizons}.h5",
            cdf_data_passenger="resources/data/load/transport_cdf.csv",
            cdf_data_freight="resources/data/load/transport_cdf.csv",
        output:
            driving_demand_passenger=DERIVED_DATA + "/transport/driving_demand_passenger_{planning_horizons}.csv",
            driving_demand_freight=DERIVED_DATA + "/transport/driving_demand_freight_{planning_horizons}.csv",
            charging_demand_passenger=DERIVED_DATA + "/transport/charging_demand_passenger_{planning_horizons}.csv",
            charging_demand_freight=DERIVED_DATA + "/transport/charging_demand_freight_{planning_horizons}.csv",
            avail_profile_passenger=DERIVED_DATA + "/transport/avail_profile_passenger_{planning_horizons}.csv",
            avail_profile_freight=DERIVED_DATA + "/transport/avail_profile_freight_{planning_horizons}.csv",
            dsm_profile=DERIVED_DATA + "/transport/dsm_profile_{planning_horizons}.csv",
        threads: 1
        resources: mem_mb=2000
        log: LOG_DIR + "/build_transport_demand/transport_demand_{planning_horizons}.log"
        script: "scripts/build_transport_demand.py"


rule build_biomass_potential:
    input:
        # from doi.org/10.1038/s41467-021-23282-x
        biomass_feedstocks = "resources/data/p_nom/41467_2021_23282_MOESM4_ESM.xlsx"
    log:
        LOGS_COMMON + "/build_biomass_potential.log"
    output:
        biomass_potential=DERIVED_COMMON+"/"+"p_nom/biomass_potential.h5"
    threads: ATLITE_NPROCESSES
    resources: mem_mb = ATLITE_NPROCESSES * 5000
    script: "scripts/build_biomass_potential.py"

# TODO add node wildcard/id
# NOTE: lifetimes are for the BASEYEAR and not brownfield construction year DateIn!
#       This could be changed if costs are merged into a single file
rule prepare_baseyear_capacities:
    """prepare inputs for add_existing_baseyear (optional in overnight mode)"""
    params:
        last_pypsa_cost_year = 2060,
        CHP_to_elec = not config.get("heat_coupling", False),
    input:
        # historical lifetimes from base year technoeconomic data
        tech_costs=path_manager.costs_dir() + f"/costs_{BASEYEAR}.csv",
        **{f"{tech}": DERIVED_COMMON + f"/existing_infrastructure/{tech}_capacity.csv"
            for tech in config['existing_capacities']['techs']},
    output:
        installed_capacities = DERIVED_DATA+ '/existing_infrastructure/capacities.csv',
    threads: 1
    resources: mem_mb=2000
    script: "scripts/prepare_existing_capacities.py"


# make sure the params will appear in the profile names
resource_class_cfg = {tech: config["renewable"][tech]["resource_classes"] for tech in config["renewable"]}
rsc_params = {key : "_".join([f"{k}{v}" for k, v in resource_class_cfg[key].items()]) for key in resource_class_cfg}
if config["foresight"] in ["overnight"]:
    add_brownfield = "-brownfield" if config["existing_capacities"].get("add", False) else ""
    add_sectors = "-sector" if config.get("sectors", {}).get("electric_vehicles", False) else ""

    rule prepare_networks:
        input:
            heat_demand_profile=DERIVED_DATA + f"/heating-cutout_{CUTOUT_NAME}/"+"heat_demand_profile_{planning_horizons}.h5",
            central_fraction="resources/data/heating/DH_city_town_2020.h5",
            solar_thermal_name=DERIVED_CUTOUT+f"/heating/solar_thermal-{config['solar_thermal_angle']}.h5",
            cop_name=DERIVED_CUTOUT+"/heating/hp_cop.h5",
            elec_load=DERIVED_DATA + "/load/regio_hrly_ac_load_{planning_horizons}.h5",
            intraday_profiles="resources/data/heating/heat_load_profile_DK_AdamJensen.csv",
            tech_costs = COSTS_DATA + "/costs_{planning_horizons}.csv",
            province_shape=DERIVED_COMMON+"/province_shapes/CHN_adm1.shp",
            biomass_potential=DERIVED_COMMON+f"{'/p_nom/biomass_potential.h5' if config["add_biomass"] else ''}",
            **{f"profile_{tech}": DERIVED_CUTOUT +f"/profile_{tech}-{rsc_params[tech]}.nc" for tech in config['renewable']},
        output:
            network_name=RESULTS_DIR+ '/prenetworks/ntwk_{planning_horizons}.nc',
        threads: 1
        resources: mem_mb=10000
        script: "scripts/prepare_network.py"

    # Only create sector network rule if electric vehicles are enabled
    if config.get("sectors", {}).get("electric_vehicles", False):
        rule add_sectors:
            input:
                network=RESULTS_DIR+ '/prenetworks/ntwk_{planning_horizons}.nc',
                transport_demand_passenger=DERIVED_DATA + "/transport/charging_demand_passenger_{planning_horizons}.csv",
                transport_demand_freight=DERIVED_DATA + "/transport/charging_demand_freight_{planning_horizons}.csv",
                driving_demand_passenger=DERIVED_DATA + "/transport/driving_demand_passenger_{planning_horizons}.csv",
                driving_demand_freight=DERIVED_DATA + "/transport/driving_demand_freight_{planning_horizons}.csv",
                avail_profile_passenger=DERIVED_DATA + "/transport/avail_profile_passenger_{planning_horizons}.csv",
                avail_profile_freight=DERIVED_DATA + "/transport/avail_profile_freight_{planning_horizons}.csv",
                dsm_profile=DERIVED_DATA + "/transport/dsm_profile_{planning_horizons}.csv",
            output:
                network=RESULTS_DIR+ '/prenetworks-sector/ntwk_{planning_horizons}.nc',
            threads: 1
            resources: mem_mb=8000
            script: "scripts/add_sectors.py"

    paidoff_caps = DERIVED_DATA + "/remind/harmonized_capacities/paid_off_capacities.csv"
    if not config["run"].get("is_remind_coupled", False):
        paidoff_caps = DERIVED_DATA+ '/existing_infrastructure/capacities.csv'
    rule add_existing_baseyear:
        params:
            baseyear = BASEYEAR,
            add_baseyear_to_assets = False,
        input:
            network=RESULTS_DIR+ f'/prenetworks{add_sectors}/' +'ntwk_{planning_horizons}.nc',
            tech_costs=COSTS_DATA + "/costs_{planning_horizons}.csv",
            cop_name=DERIVED_CUTOUT + "/heating/hp_cop.h5",
            installed_capacities = path_manager.infrastructure() + '/capacities.csv',
            paid_off_capacities_remind = paidoff_caps,
        output: RESULTS_DIR+ f'/prenetworks{add_sectors}{add_brownfield}/' +'ntwk_{planning_horizons}.nc'
        threads: 1
        resources: mem_mb=2000
        script: "scripts/add_existing_baseyear.py"

    rule solve_networks:
        params:
            solving = config["solving"],
        input:
            network_name=RESULTS_DIR+ f'/prenetworks{add_sectors}{add_brownfield}/' +'ntwk_{planning_horizons}.nc',
        output:
            network_name=RESULTS_DIR+ '/postnetworks/ntwk_{planning_horizons}.nc'
        log:
            solver = LOG_DIR + "/solve_network_postnetworks/ntwk_{planning_horizons}.log"
        threads: 4
        resources: mem_mb=90000
        script: "scripts/solve_network.py"


elif config["foresight"] == "myopic":
    rule prepare_base_networks_2020:
        input:
            edges= "resources/data/grids/edges.txt",
            edges_existing = "resources/data/grids/edges_current.csv",
            heat_demand_profile=DERIVED_DATA + f"/heating-cutout_{CUTOUT_NAME}/"+"heat_demand_profile_{planning_horizons}.h5",
            central_fraction="resources/data/heating/DH_city_town_2020.h5",
            solar_thermal_name=DERIVED_CUTOUT+f"/heating/solar_thermal-{config['solar_thermal_angle']}.h5",
            cop_name=DERIVED_CUTOUT+"/heating/hp_cop.h5",
            elec_load=DERIVED_DATA + "/load/regio_hrly_ac_load_{planning_horizons}.h5",
            # TODO: metadata for file, why does it need to be h5?
            tech_costs= COSTS_DATA + "/costs_{planning_horizons}.csv",
            province_shape=DERIVED_COMMON +"/province_shapes/CHN_adm1.shp",
            **{f"profile_{tech}": DERIVED_CUTOUT +f"/profile_{tech}-{rsc_params[tech]}.nc"
                for tech in config['renewable']},

        output:
            network_name=RESULTS_DIR+ '/prenetworks/ntwk_{planning_horizons}.nc',
        wildcard_constraints:
            planning_horizons=2020 #only applies to baseyear
        threads: 1
        resources: mem_mb=10000
        script: "scripts/prepare_base_network_2020.py"

    rule prepare_base_networks:
        input:
            edges = "resources/data/grids/edges.txt",
            biomass_potential=DERIVED_COMMON+"/"+"p_nom/biomass_potential.h5",
            cop_name= DERIVED_CUTOUT+"/heating/hp_cop.h5",
            central_fraction="resources/data/heating/DH_city_town_2020.h5",
            heat_demand_profile= DERIVED_DATA + f"/heating-cutout_{CUTOUT_NAME}/"+"heat_demand_profile_{planning_horizons}.h5",
            solar_thermal_name=DERIVED_CUTOUT + f"/heating/solar_thermal-{config['solar_thermal_angle']}.h5",
            elec_load=DERIVED_DATA + "/load/regio_hrly_ac_load_{planning_horizons}.h5",
            tech_costs= COSTS_DATA + "/costs_{planning_horizons}.csv",
            province_shape=DERIVED_COMMON+"/province_shapes/CHN_adm1.shp",
            **{f"profile_{tech}": DERIVED_CUTOUT +f"/profile_{tech}-{rsc_params[tech]}.nc"
                for tech in config['renewable']},

        output:
            network_name=RESULTS_DIR+ '/prenetworks/ntwk_{planning_horizons}.nc',
        threads: 1
        resources: mem_mb=10000
        script: "scripts/prepare_base_network.py"

    ruleorder: prepare_base_networks_2020 > prepare_base_networks

    rule add_existing_baseyear:
        params:
            baseyear = BASEYEAR,
            add_baseyear_to_assets = False,
        input:
            network=RESULTS_DIR+ '/prenetworks/ntwk_{planning_horizons}.nc',
            tech_costs=COSTS_DATA + "/costs_{planning_horizons}.csv",
            cop_name=DERIVED_CUTOUT + "/heating/hp_cop.h5",
            installed_capacities = DERIVED_DATA+ '/existing_infrastructure/capacities_{planning_horizons}.csv',
        output: RESULTS_DIR+ '/prenetworks-brownfield/ntwk_{planning_horizons}.nc'
        threads: 1
        resources: mem_mb=2000
        wildcard_constraints:
            planning_horizons=config['scenario']['planning_horizons'][0] #only applies to baseyear
        threads: 1
        script: "scripts/add_existing_baseyear.py"

    def solved_previous_horizon(wildcards):
        planning_horizons = config["scenario"]["planning_horizons"]
        i = planning_horizons.index(int(wildcards.planning_horizons))
        planning_horizon_p = str(planning_horizons[i-1])
        return RESULTS_DIR+ "/postnetworks/ntwk_" + planning_horizon_p + ".nc"

    rule add_brownfield:
        input:
            network=RESULTS_DIR+ '/prenetworks/ntwk_{planning_horizons}.nc',
            network_p=solved_previous_horizon,#solved network at previous time step
            costs="resources/data/costs/costs_{planning_horizons}.csv",
            **{f"profile_{tech}": DERIVED_CUTOUT +f"/profile_{tech}.nc"
                for tech in config['renewable']}
        output:
            network_name = RESULTS_DIR+ '/prenetworks-brownfield/ntwk_{planning_horizons}.nc',
        threads: 4
        resources: mem_mb=10000
        script: "scripts/add_brownfield.py"

    ruleorder: add_existing_baseyear > add_brownfield

    rule solve_network_myopic:
        params:
            solving = config["solving"],
        input:
            network=RESULTS_DIR+ '/prenetworks-brownfield/ntwk_{planning_horizons}.nc'
        output:
            network_name = RESULTS_DIR+ '/postnetworks/ntwk_{planning_horizons}.nc'
        log:
            solver = LOG_DIR + "/solve_network_myopic/{planning_horizons}.log"
        threads: 4
        resources: mem_mb = 80000
        script: "scripts/solve_network_myopic.py"


# run with `snakemake results/dag/rules_graph.png -f`
rule dag:
    message:
        "Creating DAG of workflow."
    output:
        dag_dot="results/dag/dag.dot",
        dag_pdf="results/dag/dag.pdf",
        dag_png="results/dag/dag.png",
        rules_dot="results/dag/rules_graph.dot",
        rules_pdf="results/dag/rules_graph.pdf",
        rules_png="results/dag/rules_graph.png",
    conda:
        "envs/environment.yaml"
    shell:
        r"""
        snakemake --dag --quiet | sed -n "/digraph/,\$p" > {output.dag_dot}
        dot -Tpdf -o {output.dag_pdf} {output.dag_dot}
        dot -Tpng -o {output.dag_png} {output.dag_dot}
        snakemake --rulegraph --quiet | sed -n "/digraph/,\$p" > {output.rules_dot}
        dot -Tpdf -o {output.rules_pdf} {output.rules_dot}
        dot -Tpng -o {output.rules_png} {output.rules_dot}
        """

onerror:
    res_dir = expand(RESULTS_DIR, **config["scenario"])[0]
    if not os.path.exists(res_dir):
        os.makedirs(res_dir)
    try:
        yaml.dump(config, open(res_dir + "/run_config.yaml", "w"))
    except TypeError as e:
        logging.warning(f"Could not copy config file: {e}")

onsuccess:
    res_dir = expand(RESULTS_DIR, **config["scenario"])[0]
    try:
        import os
        os.makedirs(res_dir, exist_ok=True)
        with open(res_dir + "/run_config.yaml", "w") as f:
            yaml.dump(config, f )
    except (TypeError, FileNotFoundError) as e:
        logging.warning(f"Could not copy config file: {e}")
